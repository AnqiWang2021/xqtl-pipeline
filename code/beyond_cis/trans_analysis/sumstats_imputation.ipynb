{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-cross",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Imputing summary statistics from LD reference panel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-christmas",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook take a list of LD reference files and a list of sumstat files from various association studies ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-default",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-consensus",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. **FIXME we need to make input as a bed file with chrom, start and end** A tab delimated table describing the path where LD per region stored, can be generated using the ld_per_region_plink step of the genotype processing module.\n",
    "\n",
    "```\n",
    "#id     dir\n",
    "chr17_60570445_65149278 /mnt/vast/hpc/csg/molecular_phenotype_calling/LD/output_npz_2/1300_hg38_EUR_LD_blocks_npz_files/ROSMAP_NIA_WGS.leftnorm.filtered.filtered.chr17_60570445_65149278.flt16.npz\n",
    "```\n",
    "\n",
    "2. A tab delimated table describing path where summary stat per chromosome stored, can be generated using the yml_generator module before the qced sumstat are generated. **FIXME: If the chrom name is zero that means the data is genome-wide**\n",
    "```\n",
    "hs3163@csglogin:/mnt/vast/hpc/csg/xqtl_workflow_testing/susie_rss$ cat /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/qced_sumstat_list.txt\n",
    "#chr    ADGWAS_Bellenguez_2022\n",
    "1       /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/ADGWAS_Bellenguez_2022.1/ADGWAS2022.chr1.sumstat.tsv\n",
    "2       /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/ADGWAS_Bellenguez_2022.2/ADGWAS2022.chr2.sumstat.tsv\n",
    "3       /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/ADGWAS_Bellenguez_2022.3/ADGWAS2022.chr3.sumstat.tsv\n",
    "4       /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/ADGWAS_Bellenguez_2022.4/ADGWAS2022.chr4.sumstat.tsv\n",
    "5       /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/ADGWAS_Bellenguez_2022.5/ADGWAS2022.chr5.sumstat.tsv\n",
    "```\n",
    "\n",
    "3. Regions we want to analyze in the format `chr:start-end`. Can be multiple of these. If not specified we will use the regions in the LD data list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-delight",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-capture",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. A RDS file containing the output susie object, the name of all variants that went through the analysis, the z score , and the LD used for the analysis.\n",
    "2. A sumstat file with additional column containing the slalom results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-overhead",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-central",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run pipeline/SuSiE_RSS.ipynb SuSiE_RSS \\\n",
    "    --ld-data test.ld.list \\\n",
    "    --sumstats /mnt/vast/hpc/csg/xqtl_workflow_testing/ADGWAS/data_intergration/ADGWAS2022/qced_sumstat_list.txt \\\n",
    "    --container containers/stephenslab.sif --impute --cwd output_impute_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-france",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cwd = path(\"output\")\n",
    "# getting the overlapped input\n",
    "parameter: ld_data = path\n",
    "parameter: sumstats = paths\n",
    "import pandas as pd\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 3\n",
    "\n",
    "parameter: lead_idx_choice = \"pvalue\"\n",
    "parameter: abf_prior_variance = 0.4\n",
    "parameter: nlog10p_dentist_s_threshold = 4\n",
    "parameter: r2_threshold = 0.6\n",
    "parameter: n = 0\n",
    "parameter: max_iter = 1000\n",
    "parameter: impute = True # Whether to impute the sumstat for all the snp in LD but not in sumstat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944952a9-0329-45f4-9e07-1aff0076fada",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[get_analysis_regions: shared = \"regional_data\"]\n",
    "# This will pair the LD matrix blocks with each of the input summary stats\n",
    "\n",
    "LD_list = pd.read_csv(LD_list,sep=\"\\t\")\n",
    "sumstat_list = pd.read_csv(sumstats,sep=\"\\t\")\n",
    "LD_list[\"#chr\"] = [x[0].replace(\"chr\", \"\") for x in  LD_list[\"#id\"].str.split(\"_\") ]\n",
    "sumstat_list[\"#chr\"] = [str(x).replace(\"chr\", \"\") for x in  sumstat_list[\"#chr\"] ]\n",
    "input_inv = LD_list.merge(sumstat_list)\n",
    "input_list = input_inv.iloc[:,[1,3]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-baseball",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[SuSiE_RSS_1]\n",
    "parameter: L = 10\n",
    "parameter: max_L = 1000\n",
    "\n",
    "depends: sos_variable(\"regional_data\")\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = 2, group_with = \"meta_info\"\n",
    "# name = f'{_input[0]:b}'.split(\".\")[-3]\n",
    "output: f'{cwd:a}/{_input[1]:bn}.{name}.unisusie_rss.fit.rds',\n",
    "        f'{cwd:a}/{_input[1]:bn}.{name}.unisusie_rss.ss_qced.tsv'    \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\", container = container, entrypoint = entrypoint\n",
    "  \n",
    "    ## Step 1: Load summary stats and LD data using the function in pecotmr::LD.R\n",
    "\n",
    "    ## Step 2: basic QC between LD and summary stats --- to correct allele flipping mainly\n",
    "  \n",
    "    ## Step 3: Perform SuSiE RSS\n",
    "  \n",
    "    ## Output is RDS file including 1) fine-mapping results and 2) the summary stats after allele flipping QC as well as the SuSiE RSS based QC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.20.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
