{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTWAS Implementation in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[global]\n",
    "# Workdir\n",
    "parameter: cwd = path(\"output\")\n",
    "# susie_table is the table of eQTL fine mapped results, which has two columns for gene and susie_fils\n",
    "parameter: susie_table = \"\"\n",
    "# This vcf is derived from the conversion of the susie rds for each gene, with the relevant information noted in the INFO column.\n",
    "#parameter: out_vcf = \"\"\n",
    "# file_table is the table of GWAS fine mapped results, which has two columns for LD blocks and susie_fils\n",
    "parameter: file_table = \"\"\n",
    "# out_file is a temporary file in the environment\n",
    "parameter: out_file = \"\"\n",
    "# the prefix of fastENLOC output \n",
    "parameter: out_pre = \"\"\n",
    "# the zipped file of out_vcf, which is derived from the conversion of the susie rds for each gene\n",
    "parameter: eqtl_vcf = \"\"\n",
    "# dataset \n",
    "parameter: tissue = ''\n",
    "# QTL data type\n",
    "parameter: QTL = 'eQTL'\n",
    "parameter: container = ''\n",
    "parameter: entrypoint={('micromamba run -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = \"5h\"\n",
    "parameter: mem = \"8G\"\n",
    "parameter: numThreads = 1\n",
    "eqtl_vcf = file_target(f\"{cwd:a}/{QTL}.susie_to_DAPG.vcf.gz\")\n",
    "import os\n",
    "if not os.path.exists(f'{cwd}/cache/'):\n",
    "    os.makedirs(f'{cwd}/cache/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SuSiE weight \n",
    "\n",
    " what is weight here, mu ?  posterior mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[susie_get_weight]\n",
    "input: ptwas_weights, gwas_path, region_list\n",
    "output: f'{cwd}/cache/input_dataframe.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTWAS scan\n",
    "This portion contains code for running the PTWAS scan as implemented in GAMBIT. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Input\n",
    "\n",
    "- eQTL Weights\n",
    "    File that contains eQTL weights (formatting is up-for-debate). Maybe column 1 is SNP and column 2 is the weight.\n",
    "- GWAS Z-Scores\n",
    "    File that contains GWAS z-scores (or what makes up the z-scores). Column 1 is SNP, column 2 can be z-scores.\n",
    "- LD reference\n",
    "- region list\n",
    "\n",
    "\n",
    "### Output\n",
    "\n",
    "Same output as GAMBIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[ptwas_scan_1]\n",
    "input: ptwas_weights, gwas_path, region_list\n",
    "output: f'{cwd}/cache/input_dataframe.txt'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    library(tidyverse)\n",
    "    library(harmonicmeanp)\n",
    "    handle_weights <- function(gwas_ids, weight_ids) {\n",
    "        return(unlist(lapply(\n",
    "            strsplit(gwas_ids, ':'),\n",
    "            function(x) {\n",
    "                POSs  <- as.double(sapply(strsplit(weight_ids, ':'), '[[', 2))\n",
    "                REFs <- sapply(strsplit(weight_ids, ':'), '[[', 3)\n",
    "                ALTs <- sapply(strsplit(weight_ids, ':'), '[[', 4)\n",
    "                for (i in 1:length(REFs)) {\n",
    "                    if (as.double(x[2]) == POSs[i]) {\n",
    "                        if (x[3] == REFs[i] & x[4] == ALTs[i]) {\n",
    "                            return(1)\n",
    "                        } else if (x[3] == ALTs[i] & x[4] == REFs[i]) {\n",
    "                            return(-1)\n",
    "                        } else if (x[3] == aflip(REFs[i]) & x[4] == aflip(ALTs[i])) {\n",
    "                            return(1)\n",
    "                        } else if (x[3] == aflip(ALTs[i]) & x[4] == aflip(REFs[i])) {\n",
    "                            return(-1)\n",
    "                        } else {\n",
    "                            return(0)\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        )))\n",
    "    }\n",
    "\n",
    "    debug_print <- function(gwas_ids, modifiers, weights, zscores, stat, denom, output) {\n",
    "        snpdf <- data.frame(\n",
    "            CHROM = sapply(strsplit(gwas_ids, ':'), '[[', 1),\n",
    "            POS = as.double(sapply(strsplit(gwas_ids, ':'), '[[', 2)),\n",
    "            VARIANT = gsub(\":\", \"_\", gwas_ids),\n",
    "            REF = sapply(strsplit(gwas_ids, ':'), '[[', 3),\n",
    "            ALT = sapply(strsplit(gwas_ids, ':'), '[[', 4),\n",
    "            MODIFIERS = modifiers,\n",
    "            WEIGHTS = weights,\n",
    "            ZSCORES = zscores) %>% arrange(POS)\n",
    "        cat(\"\\n\\nSNP info:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        write_delim(\n",
    "            snpdf,\n",
    "            output,\n",
    "            append = TRUE,\n",
    "            col_names = TRUE,\n",
    "            quote = \"none\")\n",
    "        cat(\"\\n\\nmodifiers:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$MODIFIERS, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(\"\\n\\nweights:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$WEIGHTS, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(\"\\n\\nz-stats:\\n\\n\", file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste(snpdf$ZSCORES, collapse = \" \"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste0(\"\\n\\ntest score = \", stat, \"\\n\\n\"), file = output, sep = \"\\n\", append = TRUE)\n",
    "        cat(paste0(\"\\n\\ntest variance = \", denom, \"\\n\\n\"), file = output, sep = \"\\n\", append = TRUE)\n",
    "    }\n",
    "\n",
    "    burden <- function(weight_ids, gwas_ids, weights, zscores) {\n",
    "        modifiers <- handle_weights(gwas_ids, weight_ids)\n",
    "        weights <- modifiers * weights\n",
    "        \n",
    "        stat <- sum(weights * zscores)\n",
    "        denom <- sum(weights * weights)\n",
    "        zscore <- stat/sqrt(denom)\n",
    "\n",
    "        if (length(zscores) == 1) {\n",
    "            zscore <- zscores[[1]]\n",
    "            if (weights[[1]] < 0) {\n",
    "                zscore <- zscore * -1\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        pval <- pchisq( zscore * zscore, 1, lower.tail = FALSE)\n",
    "        \n",
    "        debug_print(gwas_ids, modifiers, weights, zscores, stat, denom, paste0(output_base, \"ptwas-scan.debug\"))\n",
    "\n",
    "        return(pval)\n",
    "    }\n",
    "\n",
    "    pval_HMP <- function(pvals) {\n",
    "        # https://search.r-project.org/CRAN/refmans/harmonicmeanp/html/pLandau.html\n",
    "        pvalues <- unique(pvals)\n",
    "        L <- length(pvalues)\n",
    "        HMP <- L/sum(pvalues^-1)\n",
    "\n",
    "        LOC_L1 <- 0.874367040387922\n",
    "        SCALE <- 1.5707963267949\n",
    "\n",
    "        return(pLandau(1/HMP, mu = log(L) + LOC_L1, sigma = SCALE, lower.tail = FALSE))\n",
    "    }\n",
    "\n",
    "    pcauchy <- function(x) {\n",
    "        return(0.5 + atan(x)/pi)\n",
    "    }\n",
    "\n",
    "    qcauchy <- function(q) {\n",
    "        return(tan(pi*(q - 0.5)))\n",
    "    }\n",
    "\n",
    "    pval_ACAT <- function(pvals) {\n",
    "        if (length(pvals) == 1) {\n",
    "            return(pvals[0])\n",
    "        }\n",
    "        stat <- 0.00\n",
    "        pval_min <- 1.00\n",
    "\n",
    "        stat <- sum(qcauchy(pvals))\n",
    "        pval_min <- min(pval_min, min(qcauchy(pvals)))\n",
    "\n",
    "        return(pcauchy(stat/length(pvals), lower.tail = FALSE))\n",
    "    }\n",
    "\n",
    "\n",
    "    globalPvalue <- function(pvals, comb_method = \"HMP\", naive=FALSE) {\n",
    "        # assuming sstats has tissues as columns and rows as pvals\n",
    "        min_pval <- min(pvals)\n",
    "        n_total_tests <- pvals %>% unique() %>% length() # There should be one unique pval per tissue\n",
    "        global_pval <- if (comb_method == \"HMP\") pval_HMP(pvals) else pval_ACAT(pvals) # pval vector\n",
    "        naive_pval <- min(n_total_tests*min_pval, 1.0)\n",
    "        return(if (naive) naive_pval else global_pval) # global_pval and naive_pval\n",
    "    }\n",
    "\n",
    "            \n",
    "    generate_index <- function(variant) {\n",
    "        return(\n",
    "            unlist(lapply(\n",
    "                strsplit(variant, ':'),\n",
    "                function(x) {\n",
    "                    alleles <- list(c(x[3], x[4]), c(aflip(x[3]), aflip(x[4])), c(x[4], x[3]), c(aflip(x[4]), aflip(x[3])))\n",
    "                    alleles <- alleles[order(sapply(alleles, '[[', 1))]\n",
    "                    return(\n",
    "                        paste(\n",
    "                            c(\n",
    "                                x[1],\n",
    "                                x[2],\n",
    "                                paste(sapply(alleles, '[[', 1), collapse = \"|\"),\n",
    "                                paste(sapply(alleles, '[[', 2), collapse = \"|\")\n",
    "                            ),\n",
    "                            collapse = \":\"\n",
    "                        ))\n",
    "                })))\n",
    "    }\n",
    "            \n",
    "    aflip <- function(allele) {\n",
    "        if( allele == \"A\" ) {\n",
    "            return(\"T\")\n",
    "        }\n",
    "        else if( allele == \"C\" ) {\n",
    "            return(\"G\")\n",
    "        }\n",
    "        else if( allele == \"T\" ) {\n",
    "            return(\"A\")\n",
    "        }\n",
    "        else if( allele == \"G\" ) {\n",
    "            return(\"C\")\n",
    "        }\n",
    "        else {\n",
    "            return(\"\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ptwas_weights <- read_delim(\n",
    "        \"${ptwas_weights}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE) %>% \n",
    "        mutate(\n",
    "            uber_id = generate_index(variant))\n",
    "    gwas <- read_delim(\n",
    "        \"${gwas_path}\", delim = \"\\t\", comment = \"##\", show_col_types = FALSE) %>%\n",
    "        rename(Z = ZSCORE) %>%\n",
    "        mutate(\n",
    "            SNP_ID = gsub(\"_\", \":\", SNP_ID),\n",
    "            uber_id = generate_index(SNP_ID))\n",
    "\n",
    "    regionlist <- read_delim(\n",
    "        \"${regionlist_path}\",\n",
    "        delim = \"\\t\",\n",
    "        show_col_types = FALSE)\n",
    "    colnames(regionlist) <- c(\"#CHR\", \"start\", \"end\", \"gene_id\", \"gene_name\")\n",
    "\n",
    "    input_dataframe <- merge(\n",
    "        regionlist,\n",
    "        merge(ptwas_weights, gwas, by = c(\"uber_id\"), all = FALSE),\n",
    "        by = c(\"gene_id\"), all = FALSE)\n",
    "\n",
    "    write.table(input_dataframe, \"${_output}\", col.names = T, row.names = F, quote = F)    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[ptwas_scan_2]\n",
    "import pandas as pd\n",
    "# Extract unique values, remove 'chr', convert to int, sort, and then add 'chr' back\n",
    "input_df = file_target(f'{cwd}/cache/input_dataframe.txt')\n",
    "input_dataframe = pd.read_csv(input_df, sep='\\t')\n",
    "chroms = [\"chr\" + str(x) for x in sorted([int(chrom.replace(\"chr\", \"\")) for chrom in input_dataframe[\"#CHR.x\"].unique()])]\n",
    "\n",
    "input: chroms, group_by = 1\n",
    "output: f'{cwd}/{tissue}.{_input}.ptwas.output'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:nn}.stderr', stdout = f'{_output:nn}.stdout'\n",
    "    LDRef <- read_delim(\n",
    "        paste0(\"${vcf_path_prefix}\", tolower(\"${_input}\"), \"${vcf_path_suffix}\"),\n",
    "        delim = \"\\t\",\n",
    "        comment = \"##\",\n",
    "        show_col_types = FALSE)\n",
    "\n",
    "    LDRef$FORM_ID <- paste0(tolower(\"${_input}\"), ':', LDRef$POS, ':', LDRef$REF, ':', LDRef$ALT)\n",
    "    LDRef <- LDRef %>% \n",
    "        mutate(uber_id = generate_index(FORM_ID))\n",
    "\n",
    "    results <- input_dataframe %>%\n",
    "        filter(uber_id %in% LDRef$uber_id) %>%\n",
    "        mutate(weight = as.double(weight)) %>%\n",
    "        group_by(gene_id, tissue) %>%\n",
    "        mutate(nsnps = length(variant), burden_pval = burden(variant, SNP_ID, weight, Z)) %>%\n",
    "        ungroup() %>%\n",
    "        group_by(gene_id) %>%\n",
    "        mutate(\n",
    "            global_pval = globalPvalue(burden_pval, comb_method = \"HMP\", naive=FALSE),\n",
    "            naive_pval = globalPvalue(burden_pval, comb_method = \"HMP\", naive=TRUE),\n",
    "            min_pval = min(burden_pval)) %>%\n",
    "        ungroup()\n",
    "    \n",
    "    write_delim(\n",
    "        results %>%\n",
    "            subset(select=c(\"gene_id\", \"tissue\", \"nsnps\", \"burden_pval\", \"global_pval\", \"naive_pval\", \"min_pval\")) %>%\n",
    "            distinct(gene_id, tissue, .keep_all = TRUE),\n",
    "        \"{_output}\",\n",
    "        delim = \"\\t\",\n",
    "        append = FALSE,\n",
    "        quote = \"none\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTWAS validation \n",
    "The procedures for the PTWAS estimation and model validation that were originally implemented in Perl are now reimplemented in this R script. The unit of analysis is a single gene-trait pair. This notebook tracks how I generate the units of analysis and carry out the validation procedure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Input\n",
    "\n",
    "- Susie objects (rds files)\n",
    "- \n",
    "\n",
    "\n",
    "### Output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "[ptwas_est]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "name": "sos"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
