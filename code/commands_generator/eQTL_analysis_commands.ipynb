{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-tonight",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Bulk RNA-seq eQTL analysis\n",
    "\n",
    "This notebook provide a command generator on the XQTL workflow so it can automate the work for data preprocessing and association testing on multiple data collection as proposed.\n",
    "\n",
    "This master control notebook is mainly to serve the 8 tissues snuc_bulk_expression analysis, but should be functional on all analysis where expression data are are a tsv table in a bed.gz like format.\n",
    "\n",
    "Input:\n",
    "\n",
    "    A recipe file,each row is a data collection and with the following column:\n",
    "    \n",
    "        Theme\n",
    "            name of dataset, must be different, each uni_study analysis will be performed in a folder named after each, meta analysis will be performed in a folder named as {study1}_{study2}\n",
    "            \n",
    "            The column name must contain the # and be the first column\n",
    "    \n",
    "        genotype_file\n",
    "            {Path to a whole genome genotype file}\n",
    "        \n",
    "        molecular_pheno\n",
    "            {Path to file}\n",
    "            \n",
    "        covariate_file\n",
    "            {Path to file}\n",
    "        \n",
    "        ### note: Only data collection from the same Populations and conditions will me merged to perform Fix effect meta analysis\n",
    "        \n",
    "    A genotype list, with two column, `#chr` and  `path`\n",
    "        \n",
    "        This can be generated by the genotype session of this command generator.\n",
    "     \n",
    "    \n",
    "Output:\n",
    "    \n",
    "    1 set of association_scan result for each tissue (each row in the recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f946-36ad-45fe-80ba-0c916aee48f0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Theme\":\"MWE\",\"molecular_pheno\":\"MWE.log2cpm.tsv\",\"genotype_file\":\"MWE.bed\",\"covariate_file\":\"MWE.covariate.cov.gz\"}).to_csv(\"/mnt/mfs/statgen/snuc_pseudo_bulk/eight_tissue_analysis/MWE/command_generator\",sep = \"\\t\",index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b899d-8eb3-4f44-98a1-aa1308e35a9e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "| Theme      | molecular_pheno | genotype_file |covariate_file|\n",
    "| ----------- | ----------- |-----------||\n",
    "| MWE      | MWE.log2cpm.tsv       | /data/genotype_data/GRCh38_liftedover_sorted_all.add_chr.leftnorm.filtered.bed |MWE.covariate.cov.gz|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-parliament",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal Working Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93117226-1dca-48d6-8d51-cad1d9ce42c1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Genotype\n",
    "The MWE for the genotype session can be ran with the following commands, please be noted that a [seperated MWE genoFile]( https://drive.google.com/file/d/1zaacRlZ63Nf_oEUv2nIiqekpQmt2EDch/view?usp=sharing) was needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e3725-9d4b-4ddd-adc5-e97fd198c45f",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb plink_per_chrom \\\n",
    "    --ref_fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta    \\\n",
    "    --genoFile   mwe_genotype.vcf.gz  \\\n",
    "    --dbSNP_vcf  reference_data/00-All.vcf.gz \\\n",
    "    --sample_participant_lookup reference_data/sampleSheetAfterQC.txt -n "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95ac0d-4286-4bf4-8659-138eccb71101",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Per tissue analysis\n",
    "A MWE for the core per tissue analysis can be ran with the following commands, a complete collection of input file as well as intermediate output of the analysis can be found at [here](https://drive.google.com/drive/folders/16ZUsciZHqCeeEWwZQR46Hvh5OtS8lFtA?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd30014-f864-49ab-93ed-0e6472febc48",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb sumstat_merge \\\n",
    "    --recipe MWE.recipe   \\\n",
    "    --genotype_list plink_files_list.txt      \\\n",
    "    --annotation_gtf reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup reference_data/sampleSheetAfterQC.txt \\\n",
    "    --Association_option \"TensorQTL\"  -n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55877891-2e84-4c98-90b3-1f9ee3e24128",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/eQTL_analysis_commands.ipynb sumstat_merge \\\n",
    "    --recipe  MWE.recipe \\\n",
    "    --genotype_list plink_files_list.txt      \\\n",
    "    --annotation_gtf /mnt/mfs/statgen/snuc_pseudo_bulk/data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup /mnt/mfs/statgen/snuc_pseudo_bulk/data/reference_data/sampleSheetAfterQC.txt \\\n",
    "    --Association_option \"APEX\"   -n "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63746ef-7a60-432f-b8ae-4543c873ce57",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example for running the workflow\n",
    "This will run the workflow from via several submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b02e2-8cc6-4fd2-9624-b2b71ccfc28d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run ~/GIT/xqtl-pipeline/pipeline/eQTL_analysis_commands.ipynb sumstat_merge \\\n",
    "    --recipe  /mnt/mfs/statgen/snuc_pseudo_bulk//data/recipe_8tissue_new \\\n",
    "    --genotype_list /mnt/mfs/statgen/snuc_pseudo_bulk/data/genotype_qced/plink_files_list.txt      \\\n",
    "    --annotation_gtf /mnt/mfs/statgen/snuc_pseudo_bulk/data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup /mnt/mfs/statgen/snuc_pseudo_bulk/data/reference_data/sampleSheetAfterQC.txt \\\n",
    "    --Association_option \"TensorQTL\"   --run &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f0969-213e-41a7-b0c1-a41a74b0b7c6",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run ~/GIT/xqtl-pipeline/pipeline/eQTL_analysis_commands.ipynb sumstat_merge  \\\n",
    "    --recipe  <(cat /mnt/mfs/statgen/snuc_pseudo_bulk//data/recipe_8tissue_new  | head -2)    \\\n",
    "    --genotype_list /mnt/mfs/statgen/snuc_pseudo_bulk/data/genotype_qced/plink_files_list.txt      \\\n",
    "    --annotation_gtf /mnt/mfs/statgen/snuc_pseudo_bulk/data/reference_data/genes.reformatted.gene.gtf     \\\n",
    "    --sample_participant_lookup /mnt/mfs/statgen/snuc_pseudo_bulk/data/reference_data/sampleSheetAfterQC.txt \\\n",
    "    --factor_option \"PEER\" --Association_option \"TensorQTL\"   -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-samuel",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "## The aforementioned input recipe\n",
    "parameter: recipe = path(\".\")  # Added option to run genotype part without the recipe input, which was not used.\n",
    "## Overall wd, the file structure of analysis is wd/[steps]/[sub_dir for each steps]\n",
    "parameter:  cwd = path(\"output\")\n",
    "## Diretory to the excutable\n",
    "parameter: exe_dir = path(\"~/GIT/xqtl-pipeline/\")\n",
    "parameter: container_base_bioinfo = 'containers/bioinfo.sif'\n",
    "parameter: container_apex = 'containers/apex.sif'\n",
    "parameter: container_PEER = 'containers/PEER.sif'\n",
    "parameter: container_TensorQTL = 'containers//TensorQTL.sif'\n",
    "parameter: container_rnaquant = 'containers/rna_quantification.sif'\n",
    "parameter: container_flashpca = 'containers/flashpcaR.sif'\n",
    "parameter: container_susie = 'containers/stephenslab.sif'\n",
    "parameter: sample_participant_lookup = path\n",
    "parameter: phenotype_id_type = \"gene_name\" \n",
    "parameter: yml = path(\"csg.yml\")\n",
    "parameter: run = False\n",
    "interpreter = 'cat' if not run else 'bash'\n",
    "import pandas as pd\n",
    "if recipe.is_file():\n",
    "    input_inv = pd.read_csv(recipe, sep = \"\\t\").to_dict(\"records\")\n",
    "import os\n",
    "parameter: jobs = 50 # Number of jobs that are submitted to the cluster\n",
    "parameter: queue = \"csg\" # The queue that jobs are submitted to\n",
    "submission = f'-J {jobs} -c {yml} -q {queue}'\n",
    "\n",
    "\n",
    "## Control of the workflow\n",
    "### Factor option (PEER vs BiCV)\n",
    "parameter: factor_option = \"PEER\"\n",
    "### Association scan option (APEX vs TensorQTL)\n",
    "parameter: Association_option = \"TensorQTL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-wrestling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data Preprocessing\n",
    "### Genotype Preprocessing (Once for all tissues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933a470-2e1e-4be5-b6a4-7598479e67cf",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[dbSNP]\n",
    "parameter: dbSNP_vcf = path\n",
    "input: dbSNP_vcf\n",
    "parameter: add_chr = True\n",
    "output: f'{cwd}/reference_data/{_input:bnn}.add_chr.variants.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/pipeline//VCF_QC.ipynb dbsnp_annotate \\\n",
    "            --genoFile $[_input] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --container $[container_base_bioinfo] \\\n",
    "            $[submission if yml.is_file() else \"\" ] $[\"--add_chr\" if add_chr else \"--no-add_chr\"  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee4fb6-5aed-4f05-8efd-1496110c2221",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[VCF_QC]\n",
    "parameter: genoFile = path\n",
    "parameter: ref_fasta = path\n",
    "parameter: add_chr = True\n",
    "input: genoFile, output_from(\"dbSNP\")\n",
    "output: f'{cwd}/data_preprocessing/{_input[0]:bnn}.{\"add_chr.\" if  add_chr else False}leftnorm.filtered.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]//pipeline/VCF_QC.ipynb qc \\\n",
    "            --genoFile $[_input[0]] \\\n",
    "            --dbsnp-variants $[_input[1]] \\\n",
    "            --reference-genome $[ref_fasta] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --container $[container_base_bioinfo] \\\n",
    "            --walltime \"24h\" \\\n",
    "            $[submission if yml.is_file() else \"\" ] $[\"--add_chr\" if add_chr else \"--no-add_chr\"  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9cf57-fcad-4168-b2ae-35d41068d553",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_QC]\n",
    "# minimum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_filter = 0.05\n",
    "# maximum MAF filter to use. 0 means do not apply this filter.\n",
    "parameter: maf_max_filter = 0.0\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.1\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.1\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 1e-06\n",
    "input: output_from(\"VCF_QC\")\n",
    "output: f'{_input:n}.filtered.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]//pipeline/GWAS_QC.ipynb qc_no_prune \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --genoFile $[_input] \\\n",
    "            --maf-filter $[maf_filter] \\\n",
    "            --geno-filter $[geno_filter] \\\n",
    "            --mind-filter $[mind_filter] \\\n",
    "            --hwe-filter $[hwe_filter]   \\\n",
    "            --mem 40G  \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166a329-38f2-4da4-84cd-c4e0a51c0059",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_per_chrom]\n",
    "input: output_from(\"plink_QC\")\n",
    "output: f'{cwd:a}/data_preprocessing/{_input:bn}.plink_files_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]//pipeline/genotype_formatting.ipynb plink_by_chrom \\\n",
    "            --genoFile $[_input] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --chrom  `cut -f 1  $[_input:n].bim  | uniq | sed \"s/chr//g\"` \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59112fda-4333-4210-8481-0eb11fd32d9d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[plink_to_vcf]\n",
    "parameter: genotype_list = path\n",
    "input: genotype_list\n",
    "import pandas as pd\n",
    "parameter: genotype_file_name = pd.read_csv(_input,\"\\t\",nrows = 1).values.tolist()[0][1]\n",
    "output: f'{cwd:a}/data_preprocessing/{path(genotype_file_name):bnn}.vcf_files_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]//pipeline/genotype_formatting.ipynb plink_to_vcf \\\n",
    "            --genoFile $[_input] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c15b82-ca9e-4095-a634-0bba1eb85194",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[plink_per_gene]\n",
    "# The plink genotype file\n",
    "parameter: genoFile = path\n",
    "input: output_from(\"region_list_concat\"),genoFile\n",
    "output: f'{cwd:a}/{_input[1]:bn}.plink_files_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "        sos run $[exe_dir]/pipeline//genotype_formatting.ipynb plink_by_gene \\\n",
    "            --genoFile $[_input[1]] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --region_list  $[_input[0]] \\\n",
    "            --container $[container_base_bioinfo]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee5311-3b75-4e5a-9269-716cbfcd901c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Molecular Phenotype Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-japanese",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[annotation]\n",
    "stop_if(not recipe.is_file(), msg = \"Please specify a valid recipe as input\")\n",
    "import os\n",
    "parameter: annotation_gtf = path\n",
    "input: for_each = \"input_inv\"\n",
    "output: f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{path(_input_inv[\"molecular_pheno\"]):bn}.bed.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "  sos run $[exe_dir]/pipeline/gene_annotation.ipynb annotate_coord \\\n",
    "    --cwd $[_output:d] \\\n",
    "    --phenoFile $[_input_inv[\"molecular_pheno\"]] \\\n",
    "    --annotation-gtf $[annotation_gtf] \\\n",
    "    --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "    --container $[container_rnaquant] \\\n",
    "    --phenotype-id-type $[phenotype_id_type] $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-blame",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[region_list_generation]\n",
    "parameter: annotation_gtf = path\n",
    "input: output_from(\"annotation\"), group_with = \"input_inv\"\n",
    "output: pheno_mod = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{_input:bnn}.region_list'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/gene_annotation.ipynb region_list_generation \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --phenoFile $[_input]\\\n",
    "        --annotation-gtf $[annotation_gtf] \\\n",
    "        --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "        --container $[container_rnaquant] \\\n",
    "        --phenotype-id-type $[phenotype_id_type] $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580fc4bd-fb07-4c8f-8136-e426959e2da0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[region_list_concat]\n",
    "input: output_from(\"region_list_generation\"), group_by = \"all\"\n",
    "output: f'{cwd:a}/data_preprocessing/phenotype_data/concat.region_list'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "         cat $[_input:a] | sort | uniq > $[_output:a] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dcb67-f366-41a1-b0ca-09bd4d293601",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[phenotype_partition_by_chrom]\n",
    "input: output_from(\"annotation\"),output_from(\"region_list_generation\"), group_with = \"input_inv\"\n",
    "output: per_chrom_pheno_list = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{_input[0]:bn}.processed_phenotype.per_chrom.recipe'        \n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --phenoFile $[_input[0]:a] \\\n",
    "        --region-list $[_input[1]:a] \\\n",
    "        --container $[container_rnaquant] \\\n",
    "        --mem 4G      $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-marking",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Genotype Processing\n",
    "Since genotype is shared among the eight tissue, the QC of whole genome file is not needed. Only pca needed to be run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acb9fc-b803-4939-80c9-32cec7308170",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sample_match]\n",
    "input: for_each = \"input_inv\"\n",
    "output: f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/{sample_participant_lookup:bn}.filtered.txt',\n",
    "        geno = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/{sample_participant_lookup:bn}.filtered_geno.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/sample_matcher.ipynb filtered_sample_list \\\n",
    "        --cwd $[_output[0]:d]  \\\n",
    "        --phenoFile $[_input_inv[\"molecular_pheno\"]]  \\\n",
    "        --genoFile $[path(_input_inv[\"genotype_file\"]):n].fam  \\\n",
    "        --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "        --container $[container_rnaquant] \\\n",
    "        --translated_phenoFile $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df9826-b0b5-4c67-b52f-6f4e96a318cb",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[king]\n",
    "parameter: maximize_unrelated = False\n",
    "input:output_from(\"sample_match\")[\"geno\"], group_with = \"input_inv\"\n",
    "output: related = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/genotype_data/{path(_input_inv[\"genotype_file\"]):bn}.{_input_inv[\"Theme\"]}.related.bed',\n",
    "        unrelated = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/genotype_data/{path(_input_inv[\"genotype_file\"]):bn}.{_input_inv[\"Theme\"]}.unrelated.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/GWAS_QC.ipynb king \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input_inv[\"genotype_file\"]] \\\n",
    "    --name $[_input_inv[\"Theme\"]] \\\n",
    "    --keep-samples $[_input] \\\n",
    "    --container $[container_base_bioinfo] \\\n",
    "    --walltime 48h  $[submission if yml.is_file() else \"\" ] $[\"--maximize_unrelated\" if maximize_unrelated else \"--no-maximize_unrelated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56d62f-a560-4802-9fd8-ded3ada60a93",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[unrelated_QC]\n",
    "input: output_from(\"king\")[\"unrelated\"]\n",
    "output: unrelated_bed = f'{_input:n}.filtered.prune.bed', \n",
    "        prune = f'{_input:n}.filtered.prune.in'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/GWAS_QC.ipynb qc \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input] \\\n",
    "    --exclude-variants /mnt/mfs/statgen/snuc_pseudo_bulk/Ast/genotype/dupe_snp_to_exclude \\\n",
    "    --maf-filter 0.05 \\\n",
    "    --container $[container_base_bioinfo] \\\n",
    "    --mem 40G  $[submission if yml.is_file() else \"\" ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109d434-a4f0-4543-b912-1f2e64b0c54a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[related_QC]\n",
    "input: output_from(\"king\")[\"related\"],output_from(\"unrelated_QC\")[\"prune\"]\n",
    "output: f'{_input[0]:n}.filtered.extracted.bed'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/GWAS_QC.ipynb qc_no_prune \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input[0]] \\\n",
    "    --maf-filter 0 \\\n",
    "    --geno-filter 0 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe-filter 0 \\\n",
    "    --keep-variants $[_input[1]]  \\\n",
    "    --container $[container_base_bioinfo]  \\\n",
    "    --mem 40G   $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-opening",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb7095-247e-44eb-aaa3-0f050c358b73",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pca]\n",
    "input: output_from(\"unrelated_QC\")[\"unrelated_bed\"],group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.rds',\n",
    "        f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.scree.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     sos run $[exe_dir]/pipeline/PCA.ipynb flashpca \\\n",
    "        --cwd $[_output:d] \\\n",
    "        --genoFile $[_input] \\\n",
    "        --container $[container_flashpca]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd276535-2566-4b17-b27d-27688e8c6ef7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[projected_sample]\n",
    "# The percentage of PVE explained\n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"related_QC\"),output_from(\"pca\"), group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input[0]:bn}.pca.projected.rds',\n",
    "        f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input[0]:bn}.pca.projected.scree.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/PCA.ipynb project_samples \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --genoFile $[_input[0]] \\\n",
    "            --pca-model  $[_input[1]] \\\n",
    "            --maha-k `awk '$3 < $[PVE_treshold]' $[_input[2]] | tail -1 | cut -f 1  ` \\\n",
    "            --container $[container_flashpca]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589ea80-e69f-4d3b-8cb7-9ccf12f3af54",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_pca_covariate]\n",
    "# The percentage of PVE explained\n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"projected_sample\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{path(_input_inv[\"covariate_file\"]):bn}.pca.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/covariate_formatting.ipynb merge_pca_covariate \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --pcaFile $[_input[0]:a] \\\n",
    "            --covFile  $[path(_input_inv[\"covariate_file\"])] \\\n",
    "            --tol_cov 0.3  \\\n",
    "            --k `awk '$3 < $[PVE_treshold]' $[_input[1]] | tail -1 | cut -f 1 ` \\\n",
    "            --container $[container_base_bioinfo] $[submission if yml.is_file() else \"\" ] --name $[_output:bn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e45bf9-eb9a-45b6-b3b5-d275f1821f03",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[resid_exp]\n",
    "input: output_from(\"merge_pca_covariate\"),output_from(\"annotation\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/resid_phenotype/{_input[1]:bnn}.{_input[0]:bn}.resid.bed.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/covariate_formatting.ipynb compute_residual \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --phenoFile $[_input[1]:a] \\\n",
    "            --covFile  $[_input[0]:a] \\\n",
    "            --container $[container_base_bioinfo] $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-indianapolis",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[factor]\n",
    "parameter: N = 0\n",
    "input: output_from(\"resid_exp\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{_input[0]:bnn}.{factor_option}.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "         sos run $[exe_dir]/pipeline/$[factor_option]_factor.ipynb $[factor_option] \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --phenoFile $[_input[0]:a]  \\\n",
    "            --container $[container_apex if factor_option == \"BiCV\" else container_PEER]  \\\n",
    "            --walltime 24h \\\n",
    "            --numThreads 8 \\\n",
    "            --iteration 1000 \\\n",
    "            --N $[N]  $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfbba48-5d7b-4217-93cc-8d91943ad45d",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_factor_covariate]\n",
    "# The percentage of PVE explained\n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"factor\"),output_from(\"merge_pca_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{_input[0]:bn}.cov.gz'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/covariate_formatting.ipynb merge_factor_covariate \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --factorFile $[_input[0]:a] \\\n",
    "            --covFile  $[_input[1]:a] \\\n",
    "            --container $[container_base_bioinfo] $[submission if yml.is_file() else \"\" ] --name $[_output:bn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee34865-5d82-4c29-aa61-78d3f9051dbc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Association Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457e6af-dec0-475e-aafc-4db2d43c1945",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL]\n",
    "# The number of minor allele count as treshold for the analysis\n",
    "parameter: MAC = 0\n",
    "# The minor allele frequency as treshold for the analysis, overwrite MAC\n",
    "parameter: maf_threshold = 0\n",
    "parameter: genotype_list = path\n",
    "input: genotype_list, output_from(\"phenotype_partition_by_chrom\"),output_from(\"merge_factor_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd:a}/association_scan/{_input_inv[\"Theme\"]}/TensorQTL/TensorQTL.cis._recipe.tsv'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/TensorQTL.ipynb cis \\\n",
    "        --genotype-list $[_input[0]]   \\\n",
    "        --phenotype-list $[_input[1]] \\\n",
    "        --covariate-file $[_input[2]]    \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --container $[container_TensorQTL] $[submission if yml.is_file() else \"\" ] $[f'--MAC {MAC}' if MAC else \"\"] $[f'--maf_threshold {maf_threshold}' if maf_threshold else \"\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2359b0-c9f2-4100-a26a-53820b8d4e12",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[APEX]\n",
    "parameter: genotype_list = path\n",
    "input: output_from(\"plink_to_vcf\"), output_from(\"phenotype_partition_by_chrom\"),output_from(\"merge_factor_covariate\"),group_with = \"input_inv\"\n",
    "output: f'{cwd:a}/association_scan/{_input_inv[\"Theme\"]}/APEX/APEX_QTL_recipe.tsv'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/APEX.ipynb cis \\\n",
    "        --genotype-list $[_input[0]]   \\\n",
    "        --phenotype-list $[_input[1]] \\\n",
    "        --covariate-file $[_input[2]]    \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --container $[container_apex] $[submission if yml.is_file() else \"\" ] --name $[_input[1]:bnn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0392f-5b59-4fa7-a9af-cee52847feed",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SuSiE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c000a36-03f6-48c6-ab8f-0feaf85f34f0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[UniSuSiE]\n",
    "input: output_from(\"plink_per_gene\"), output_from(\"annotation\"),output_from(\"factor\"), output_from(\"region_list_concat\"), group_by = \"all\"\n",
    "output: f'{cwd:a}/Fine_mapping/UniSuSiE/UniSuSiE_recipe.tsv'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\"\n",
    "    sos run $[exe_dir]/pipeline/SuSiE.ipynb uni_susie \\\n",
    "        --genoFile $[_input[0]]   \\\n",
    "        --phenoFile $[\" \".join([str(x) for x in _input[1:len(input_inv)+1]])] \\\n",
    "        --covFile $[\" \".join([str(x) for x in  _input[len(input_inv)+1:len(input_inv)*2+1]])]  \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --tissues $[\" \".join([x[\"Theme\"] for x in input_inv])] \\\n",
    "        --region-list $[_input[3]] \\\n",
    "        --container $[container_susie] $[submission if yml.is_file() else \"\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43001652-ca24-4e9b-b124-14af22796cbe",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Sumstat Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d8716-e235-4834-ab86-66c04c0bcad2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[yml_generation]\n",
    "input: output_from(Association_option), group_by = \"all\"\n",
    "output: f'{cwd:a}/data_intergration/{Association_option}/qced_sumstat_list.txt',f'{cwd:a}/data_intergration/{Association_option}/yml_list.txt'\n",
    "script: interpreter = interpreter, expand = \"$[ ]\"\n",
    "        sos run $[exe_dir]/pipeline/yml_generator.ipynb yml_list \\\n",
    "            --sumstat-list $[_input] \\\n",
    "            --cwd  $[_output[1]:d] --name $[\" \".join([str(x).split(\"/\")[-3] for x in _input])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12910c2b-22bf-4d55-a005-27838d8d90e6",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sumstat_merge]\n",
    "input: output_from(\"yml_generation\")\n",
    "script: interpreter = interpreter, expand = \"$[ ]\"\n",
    "      sos run  $[exe_dir]/pipeline/summary_stats_merger.ipynb     \\\n",
    "            --sumstat-list $[_input[0]]    \\\n",
    "            --yml-list $[_input[1]]    \\\n",
    "            --cwd $[_input[0]:d]  $[submission if yml.is_file() else \"\" ] --mem 50G --walltime 48h \n",
    "          \n",
    "      sos run  $[exe_dir]/pipeline/summary_stats_merger.ipynb    sumstat_to_vcf  \\\n",
    "         --sumstat-list $[_input[0]]    \\\n",
    "         --yml-list $[_input[1]]    \\\n",
    "         --cwd $[_input[0]:d]  $[submission if yml.is_file() else \"\" ] --mem 50G --walltime 48h "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
