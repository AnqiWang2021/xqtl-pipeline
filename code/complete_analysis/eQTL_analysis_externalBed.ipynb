{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-tonight",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Bulk RNA-seq eQTL analysis, external_bed\n",
    "\n",
    "This notebook provide a master control on the XQTL workflow so it can automate the work before data preprocessing on multiple data collection as proposed.\n",
    "\n",
    "This master control notebook is mainly to serve the 8 tissues snuc_bulk_expression analysis, but should be functional on all analysis where expression data an\n",
    "\n",
    "Input:\n",
    "    A recipe file,each row is a data collection and with the following column:\n",
    "    \n",
    "    Theme\n",
    "        name of dataset, must be different, each uni_study analysis will be performed in a folder named after each, meta analysis will be performed in a folder named as {study1}_{study2}\n",
    "            \n",
    "        The column name must contain the # and be the first column\n",
    "    \n",
    "    genotype_file\n",
    "        {Path to a whole genome genotype file}\n",
    "    \n",
    "    molecular_pheno\n",
    "        {Path to file}\n",
    "        \n",
    "    covariate_file\n",
    "        {Path to file}\n",
    "    \n",
    "    ### note: Only data collection from the same Populations and conditions will me merged to perform Fix effect meta analysis\n",
    "    \n",
    "Output:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-stanley",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-leone",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-casting",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-acoustic",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-pantyhose",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({\"ld_file_prefix\" : [\"/mnt/mfs/statgen/neuro-twas/mv_wg/cache_arch/cache/geneTpmResidualsAgeGenderAdj_rename.\",\"/mnt/mfs/statgen/neuro-twas/mv_wg/cache_arch/cache/geneTpmResidualsAgeGenderAdj_rename.\"],\n",
    "               \"ld_file_surfix\" : [\".merged.ld.rds\",\".merged.ld.rds\"]}).to_csv(\"~/GIT/ADSPFG-xQTL/MWE/LD_Recipe\",sep = \"\\t\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-reward",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "nohup sos run ./eQTL_analysis_externalBed.ipynb factor \\\n",
    "    --recipe mwe.recipe \\\n",
    "    --annotation_gtf data/reference_data/genes.reformatted.gene.gtf --sample_participant_lookup data/sampleSheetAfterQC.txt \\\n",
    "    --cwd ./  &\n",
    "\n",
    "nohup sos run ./eQTL_analysis_externalBed.ipynb TensorQTL \\\n",
    "    --recipe mwe.recipe \\\n",
    "    --annotation_gtf data/reference_data/genes.reformatted.gene.gtf --sample_participant_lookup data/sampleSheetAfterQC.txt \\\n",
    "    --genotype_list mwe.genotype_chrom_list \\\n",
    "    --cwd ./  &\n",
    "\n",
    "nohup sos run ./eQTL_analysis_externalBed.ipynb rds_creation \\\n",
    "    --recipe mwe.recipe \\\n",
    "    --annotation_gtf data/reference_data/genes.reformatted.gene.gtf --sample_participant_lookup data/sampleSheetAfterQC.txt \\\n",
    "    --genotype_list mwe.genotype_gene_list \\\n",
    "    --cwd ./  &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-conservative",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-parliament",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Example for running the workflow\n",
    "This will run the workflow from via several submission and save the output to nohup.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-sucking",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-initial",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dominant-spyware",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Other example workflow:\n",
    "These command run each of the substep to test them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-merit",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-samuel",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "## The aforementioned input recipe\n",
    "parameter: recipe = path\n",
    "## Overall wd, the file structure of analysis is wd/[steps]/[sub_dir for each steps]\n",
    "parameter:  cwd = path(\".\")\n",
    "## Diretory to the excutable\n",
    "parameter: exe_dir = path(\"~/GIT/xqtl-pipeline/\")\n",
    "parameter: container = '/mnt/mfs/statgen/containers/twas_latest.sif'\n",
    "parameter: container_base_bioinfo = '/mnt/mfs/statgen/containers/bioinfo.sif'\n",
    "parameter: container_apex = '/mnt/mfs/statgen/containers/apex.sif'\n",
    "parameter: container_PEER = '/mnt/mfs/statgen/containers/PEER.sif'\n",
    "parameter: container_TensorQTL = '/mnt/mfs/statgen/containers//TensorQTL.sif'\n",
    "parameter: container_rnaquant = '/mnt/mfs/statgen/containers/rna_quantification.sif'\n",
    "parameter: container_flashpca = '/mnt/mfs/statgen/containers/flashpca.sif'\n",
    "parameter: annotation_gtf = path\n",
    "parameter: sample_participant_lookup = path\n",
    "parameter: phenotype_id_type = \"gene_name\" \n",
    "parameter: yml = path(\"csg.yml\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-wrestling",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Molecular Phenotype Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-circulation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fifth-holder",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "### Molecular Phenotype Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-relationship",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[Normalization]\n",
    "#import os\n",
    "#input: for_each = \"input_inv\"\n",
    "#skip_if( os.path.exists(_input_inv[\"molecular_pheno\"]))\n",
    "#output: f'{cwd:a}/data_preprocessing/normalization/{name}.mol_phe.bed.gz'\n",
    "#bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "#    sos run $[exe_dir]/data_preprocessing/phenotype/GWAS_QC.ipynb output \\\n",
    "#        --counts_gct $[_input_inv[\"genecount_table\"]] \\\n",
    "#        --tpm_gct $[_input_inv[\"geneTpm_table\"]] \\\n",
    "#        --sample_participant_lookup $[_input_inv[\"sample_index\"]] \\\n",
    "#        --vcf_chr_list $[_input_inv[\"vcf_chr_list\"]] \\\n",
    "#        --container $[container_gtex] \\\n",
    "#        --name $[_input_inv[\"Theme\"]] \\\n",
    "#        --wd $[wd:a]/data_preprocessing/normalization/ \\\n",
    "#        --container $[container_base_bioinfo] \\\n",
    "#        -J 200 -q csg -c  $[yml] &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-japanese",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[annotation]\n",
    "## Must be ran with internet connection\n",
    "import os\n",
    "input: for_each = \"input_inv\"\n",
    "output: f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{_input_inv[\"Theme\"]}.{path(_input_inv[\"molecular_pheno\"]):bn}.bed.gz'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "  sos run $[exe_dir]/pipeline/gene_annotation.ipynb annotate_coord \\\n",
    "    --cwd $[_output:d] \\\n",
    "    --phenoFile $[_input_inv[\"molecular_pheno\"]] \\\n",
    "    --annotation-gtf $[annotation_gtf] \\\n",
    "    --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "    --container $[container_rnaquant] \\\n",
    "    --phenotype-id-type $[phenotype_id_type] -J 1 -c $[yml] -q csg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-blame",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[region_list_generation]\n",
    "input: output_from(\"annotation\"), group_with = \"input_inv\"\n",
    "output: pheno_mod = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{_input_inv[\"Theme\"]}.region_list'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/gene_annotation.ipynb region_list_generation \\\n",
    "        --cwd $[_output:d]  \\\n",
    "        --phenoFile $[_input:d]\\\n",
    "        --annotation-gtf $[annotation_gtf] \\\n",
    "        --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "        --container $[container_rnaquant] \\\n",
    "        --phenotype-id-type $[phenotype_id_type] -J 1 -c $[yml] -q csg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dcb67-f366-41a1-b0ca-09bd4d293601",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[phenotype_partition_by_chrom]\n",
    "input: output_from(\"annotation\"),output_from(\"region_list_generation\"), group_with = \"input_inv\"\n",
    "output: per_chrom_pheno_list = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/phenotype_data/{_input_inv[\"Theme\"]}.per_chrom_pheno_list'        \n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "sos run $[exe_dir]/pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd $[_output:d]  \\\n",
    "    --phenoFile $[_input[0]:d] \\\n",
    "    --region-list $[_input[1]:d] \\\n",
    "    --container $[container_rnaquant] \\\n",
    "    -J 30 -c $[yml] -q csg --mem 4G "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-marking",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Genotype Processing\n",
    "Since genotype is shared among the eight tissue, the QC of whole genome file is not needed. Only pca needed to be run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79acb9fc-b803-4939-80c9-32cec7308170",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sample_match]\n",
    "input:for_each = \"input_inv\"\n",
    "output: f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/{sample_participant_lookup:n}.filtered.txt',\n",
    "        geno = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/{sample_participant_lookup:n}.filtered_geno.txt'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/sample_matcher.ipynb filtered_sample_list \\\n",
    "        --cwd $[_output[0]:d]  \\\n",
    "        --phenoFile $[_input_inv[\"molecular_pheno\"]]  \\\n",
    "        --genoFile $[_input_inv[\"genotype_file\"]]  \\\n",
    "        --sample-participant-lookup $[sample_participant_lookup] \\\n",
    "        --container $[container_rnaquant] \\\n",
    "        --translated_phenoFile -J 1 -c $[yml] -q csg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df9826-b0b5-4c67-b52f-6f4e96a318cb",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[king]\n",
    "input:output_from(\"sample_match\"), group_with = \"input_inv\"\n",
    "output: related = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/genotype_data/{path(_input_inv[\"genotype_file\"]):bn}.related.bed',\n",
    "        unrelated = f'{cwd:a}/data_preprocessing/{_input_inv[\"Theme\"]}/genotype_data/{path(_input_inv[\"genotype_file\"]):bn}.unrelated.bed'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/GWAS_QC.ipynb king \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input_inv[\"genotype_file\"]] \\\n",
    "    --name $[_input_inv[\"Theme\"]] \\\n",
    "    --keep-samples $[_input] \\\n",
    "    --container $[container_base_bioinfo]  -J 1 -c $[yml] -q csg --walltimes 48h -s force "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56d62f-a560-4802-9fd8-ded3ada60a93",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[unrelated_QC]\n",
    "input: output_from(\"king\")[\"unrelated\"]\n",
    "output: unrelated_bed = f'{_input:n}.filtered.prune.bed', \n",
    "        prune = f'{_input:n}.filtered.prune.in'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/GWAS_QC.ipynb qc \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile$[_input] \\\n",
    "    --exclude-variants /mnt/mfs/statgen/snuc_pseudo_bulk/Ast/genotype/dupe_snp_to_exclude \\\n",
    "    --maf-filter 0.05 \\\n",
    "    --container $[container_base_bioinfo] -J 1 -c $[yml] -q csg --mem 40G  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109d434-a4f0-4543-b912-1f2e64b0c54a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[related_QC]\n",
    "input: output_from(\"king\")[\"related\"],output_from(\"unrelated_QC\")[\"prune\"]\n",
    "output: f'{_input:n}.filtered.prune.bed'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/GWAS_QC.ipynb qc \\\n",
    "    --cwd $[_output[0]:d] \\\n",
    "    --genoFile $[_input[0]] \\\n",
    "    --exclude-variants /mnt/mfs/statgen/snuc_pseudo_bulk/Ast/genotype/dupe_snp_to_exclude \\\n",
    "    --maf-filter 0 --geno-filter 0 --mind-filter 0.1 --hwe-filter 0 \\\n",
    "    --keep-variants $[_input[1]]  \\\n",
    "    --container $[container_base_bioinfo] -J 1 -c $[yml] -q csg --mem 40G  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-opening",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb7095-247e-44eb-aaa3-0f050c358b73",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[pca]\n",
    "input: output_from(\"unrelated_QC\")[\"unrelated_bed\"],group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.rds',\n",
    "        f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.scree.txt'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "     sos run $[exe_dir]/pipeline/PCA.ipynb flashpca \\\n",
    "        --cwd $[_output:d] \\\n",
    "        --genoFile $[_input] \\\n",
    "        --container $[container_flashpca] -J 1 -c $[yml] -q csg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd276535-2566-4b17-b27d-27688e8c6ef7",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[projected_sample]\n",
    "# The percentage \n",
    "parameter: PVE_treshold = 0.7\n",
    "input: output_from(\"related_QC\"),output_from(\"pca\"), group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/pca/{_input:bn}.pca.projected.rds'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/PCA.ipynb project_samples \\\n",
    "            --cwd $[_output:d] \\\n",
    "            --genoFile $[_input[0]] \\\n",
    "            --pca-model  $[_input[1]] \\\n",
    "            --maha-k `awk '$3 < $[PVE_treshold]' $[_input[2]] | tail -1 | cut -f 1  ` \\\n",
    "            --k `awk '$3 < $[PVE_treshold]' $[_input[2]] | tail -1 | cut -f 1 ` \\\n",
    "            --container $[container_flashpca] -J 1 -c $[yml] -q csg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589ea80-e69f-4d3b-8cb7-9ccf12f3af54",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_pca_covariate]\n",
    "input: output_from(\"projected_sample\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{_input_inv[\"covariate_file\"]:bn}.pca.cov.gz'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "sos run $[exe_dir]/pipeline/covariate_formatting.ipynb merge_pca_covariate \\\n",
    "    --cwd $[_output:d] \\\n",
    "    --pcaFile $[_input:a] \\\n",
    "    --covFile  $[_input_inv[\"covariate_file\"]:bn] \\\n",
    "    --container $[container_base_bioinfo] -J 1 -c $[yml] -q csg &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-indianapolis",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[factor]\n",
    "input: output_from(\"merge_pca_covariate\"),output_from(\"annotation\"),group_with = \"input_inv\"\n",
    "output: f'{cwd}/data_preprocessing/{_input_inv[\"Theme\"]}/covariates/{_input:bn}.'\n",
    "#task: trunk_workers = 1, trunk_size = 1, walltime = '24h',  mem = '40G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    " sos run $[exe_dir]/pipeline/BiCV_factor.ipynb BiCV \\\n",
    "    --cwd $[_output:d] \\\n",
    "    --phenoFile $[_input[1]:a]  \\\n",
    "    --covFile  $[_input[0]:a]  \\\n",
    "    --container $[container_APEX]  -J 1 -c $[yml] -q csg --walltime 24h --numThreads 8 --iteration 1000 --N 60  &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee34865-5d82-4c29-aa61-78d3f9051dbc",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Association scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457e6af-dec0-475e-aafc-4db2d43c1945",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[TensorQTL]\n",
    "parameter: genotype_list = path\n",
    "input: genotype_list, output_from(\"phenotype_partition_by_chrom\"),output_from(\"factor\"),group_with = \"input_inv\"\n",
    "output: f'{cwd:a}/Association_scan/{_input_inv[\"Theme\"]}/TensorQTL_recipe.tsv'\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/TensorQTL.ipynb TensorQTL_cis \\\n",
    "        --genotype_file_list $[_input[0]]   \\\n",
    "        --molecular_pheno_list $[_input[1]] \\\n",
    "        --covariate $[_input[2]]    \\\n",
    "        --wd $[_output:d]  \\\n",
    "        --container $[container_TensorQTL] -J 30 -c csg.yml -q csg  &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ad50e-60e3-43b3-af45-2aea1158a7f9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "## RDS creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43d8716-e235-4834-ab86-66c04c0bcad2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[rds_creation]\n",
    "parameter: genotype_list = path\n",
    "input: genotype_list, output_from(\"annotation\"),output_from(\"factor\"),output_from(\"region_list_generation\"),group_with = \"input_inv\"\n",
    "bash:  expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    sos run $[exe_dir]/pipeline/per_gene_data_merger.ipynb data_merger \\\n",
    "        --genoFile $[_input[0]]   \\\n",
    "        --phenoFile $[_input[1]] \\\n",
    "        --covFile $[_input[2]]    \\\n",
    "        --cwd $[_output:d]  --region-list $[_input[3]] \\\n",
    "        --container $[container_TensorQTL] -J 30 -c csg.yml -q csg  &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Markdown",
     "markdown",
     "markdown",
     "",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
